---
layout: post
title: "Day 11 – Literature Review, Derivatives, and Machine Learning" 
date: 2025-06-10
author: Ato Bhatta
permalink: /day11.html 
tags: ["AI in Healthcare", "Glioblastoma", "Derivatives", "Partial Derivatives", "Machine Learning", "Google Scholar", "Team Learning"]
what_i_learned: |
  We began the day with a review of the literature on AI applications in healthcare. A Google Scholar article titled "Applications of AI in Identifying and Predicting Glioblastoma and Related Brain Cancers Using Genetic Biomarkers" was the one I selected after looking through a number of sites. Reading about how genetic data is being used to educate artificial intelligence, specifically machine learning algorithms, to identify complicated brain tumors like glioblastoma—a particularly aggressive and malignant disease—was fascinating.

  The study described how AI systems can identify and even forecast the risk of glioblastoma by using biomarkers, which are genetic signs found in patient data. I became aware of how potent and life-saving AI can be in actual healthcare after reading about a number of machine learning models and datasets used in medical diagnosis. I now have a better idea of how to organize our own research project, what kinds of problem statements to concentrate on, and how to demonstrate practical AI applications with scholarly backing.

  We next moved on to the foundations of mathematics, particularly derivatives. In order to determine the rate of change for functions with multiple variables—a critical component in machine learning model training—we studied the fundamentals of partial derivatives. Knowing how to calculate gradients makes it easier to understand how learning algorithms minimize cost functions by optimizing weights.
  
  We resumed viewing our machine learning YouTube tutorial in the second half of the session. Concepts like supervised learning, linear regression prediction, and how gradient descent modifies parameters to lower error were all reinforced by this. As we relate these theoretical concepts to actual cases and mathematical tools like derivatives, they begin to make more sense.

blockers: |
  Connecting partial derivatives to the gradient descent code was one of the challenges we encountered today. Additionally, we initially had trouble understanding several of the biomedical words used in the research paper.

reflection: |
  I now have a better understanding of how theory and research relate to real-world machine learning. I learned from reading a study on glioblastoma that artificial intelligence is about solving actual problems that affect people's lives, not just writing code. Additionally, it taught me how to choose a subject that is worthy of research, which will direct our next initiatives.

  Understanding partial derivatives made it easier to understand how algorithms learn. I no longer view machine learning as a mystery; instead, I can understand how gradients direct the model's development with each iteration. It seemed like a turning point, and I can't wait to continue expanding on this mathematical framework.

  The learning process was enhanced and broadened by watching tutorials, reading research, and putting theory into practice through group discussions. I feel like I'm getting closer to creating meaningful models that could further a larger goal, such as early disease detection or healthcare solutions, rather than merely functional ones.
---

