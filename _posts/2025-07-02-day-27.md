---
layout: post  
title: "Day 27 â€“ Algorithm Testing and Presentation Preparation"  
date: 2025-07-02  
author: Ato Bhatta  
permalink: /day27.html  
tags: ["Machine Learning", "Model Accuracy", "XGBoost", "KNN", "Data Visualization", "Presentation Prep"]
what_i_learned: |
  Today, we tested ten different supervised machine learning models to classify brain tumor data. The models included Logistic Regression, Decision Tree, Random Forest, SVM, Gradient Boosting, GaussianNB, XGBoost, LDA, AdaBoost, and KNN. After training and testing, we compared their accuracies and visualized the results in a bar graph. XGBoost and Gradient Boosting showed the highest performance, while LDA was among the lowest. This helped us better understand how different models behave on medical data. Afterward, we focused on building our presentation, summarizing contributions, challenges, and solutions with the help of mentors and visual tools.

blockers: |
  No blockers today.
  
reflection: |
  I was better able to understand how model accuracy changes based on the method by comparing the performance of ten machine learning methods.  The visual aid made those distinctions easier to comprehend.  As I prepared the presentation, I also thought about how far we've come, from reading articles and analyzing data to creating models and crafting our introduction.  Seeing every component of our idea come together is exciting.
---
