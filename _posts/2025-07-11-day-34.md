---
layout: post  
title: "Day 34 â€“ Testing ML Algorithms and Accuracy Comparison"  
date: 2025-07-11  
author: Ato Bhatta  
permalink: /day34.html  
tags: ["Machine Learning", "Random Forest", "Gradient Boosting", "Model Evaluation", "Classification"]

what_i_learned: |
  Today, we concentrated on using our brain tumor dataset to apply several machine learning techniques.  We compared the two Random Forest Classifiers' performance in tumor type classification.  We received a 100 accuracy rating from Graduent Boosting.  In order to analyze the precision, recall, and F1-scores for every class, we also produced categorization reports.  Understanding the model's performance beyond accuracy was made easier with the help of this phase.
  These experiments helped us see how different models behave with the same dataset and gave us insight into how feature quality and dataset structure influence model results. 

blockers: |
  One of the main concerns was whether the 100% accuracy from Gradient Boosting indicated overfitting. We will need to test this further on different validation sets or perform cross-validation to ensure it's a reliable result.

reflection: |
  I became more at ease utilizing scikit-learn models and deciphering evaluation criteria after running these algorithms.  It also demonstrated how results can be significantly impacted by adjusting or selecting alternative algorithms.  It was amazing to see great accuracy, but I also learnt that before deciding which model is best, caution and extensive validation are crucial.
---
